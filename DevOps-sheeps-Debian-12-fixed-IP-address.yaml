# Sheeps. Worker nodes for a Web Dev cluster
#
# Usage:
#    ansible-playbook --ask-vault DevOps-xxx.yaml
#
---
- name: Cloning MVs. Sheeps for DevOps cluster
  hosts: localhost
  gather_facts: false

# Variables
# --

# encrypted file with ansible-vault with the variable
# {{ ovirt_password }} storing the IaaS ULL password

  vars_files:
    - alu0101056944ull.yaml

# SSH key for the user "ansible" 

  vars:
    ssh_keys: ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC/cjSAcKEUB68krsUm7SQdfFbYHRuDQ2PVir8zhDqE9FvkB/BtyoscbExqqMgLJ+nsnBBdYzBpGJgo1Dzj1dacYVSCKQWaBbQGOoEmJfyIOiLGuN/e4KLRzZCTkrlYZGVx8ICjqE8aOmSrZj3nmDmkO8z4DAKKR6PS6b+3s6hcegQph9VCKqOKm71poz4iPTLrqIuSPCYy1dEs5tHaimtPxzitXNaES5Wc4eZqYNPSuqIXOVWOHwSuH1TTiu7XFH85QrDOmkdICUZW/wxUyaNNO3uS1ksGKcjMIjFhj4JFnsNIU5RgwTM6umfFG952icKJQjmvsqAN1X3ymXaxEGgCF7oooQOmn5nQxuRuHv/iUJvqSKRi9xYQWONtAv2x4YOFar/5gTslYU1No+S768FpC5rGlsFC8YN/D8inbBKGu9URGk0/tNVHsXahN6/M4XWFU3Yp7KPMcRhObleA2s7QXN55hSGdhWO3M4WB5RdOBEkhFFI9CfBS9NXZPB4Ir/c= manager@ubuntu

# IaaS user (change vblanco by aluxxx...)

    ovirt_login: alu0101056944@ULL

# Distro
    distro: debian-12-sinred-cloudinit

# Node names to create  (in these case, two "sheeps")

    prefix: DevOps-Profesor
    nodes:
      - name: DevOps-worker1
        ip: 192.168.23.9
      - name: DevOps-worker2
        ip: 192.168.23.10
      - name: DevOps-worker3
        ip: 192.168.23.11
      - name: DevOps-controllerlb
        ip: 192.168.23.5
      - name: DevOps-controller1
        ip: 192.168.23.6
      - name: DevOps-controller2
        ip: 192.168.23.7
      - name: DevOps-controller3
        ip: 192.168.23.8
      - name: DevOps-loadbalancer
        ip: 192.168.23.4
      - name: DevOps-k8s_admin
        ip: 192.168.23.3

# Private network profile assigned to each Lab group
# See IaaS ULL portal

    node_nics: 
      - name: nic1
        profile_name: DOCP2P-4014

# Tasks
# ------

  tasks:
    - name: Login to IaaS
      ovirt_auth:
        url: https://iaas.ull.es/ovirt-engine/api
        insecure: yes
        username: "{{ ovirt_login }}"
        password: "{{ ovirt_password }}"
        headers:
          filter: true

    - name: Create a VM
      ovirt_vm:
        auth: "{{ ovirt_auth }}"
        cluster: Cluster-Rojo
        name: "{{ prefix }}-{{ item.name }}"
        cpu_cores: 1
        cpu_sockets: 2
        memory: 2GiB
        template: "{{ distro }}"
        nics: "{{ node_nics }}"
        state: present
        wait: yes
      with_items: "{{ nodes }}"
    
    - name: Update VM via cloud-init
      ovirt_vm:
        auth: "{{ ovirt_auth }}"
        name: "{{ prefix }}-{{ item.name }}"
        state: running
        cloud_init_nics:
          - nic_name: ens3
            nic_boot_protocol: static
            nic_ip_address: "{{ item.ip }}"
            nic_netmask: 255.255.255.0
            nic_gateway: 192.168.23.1
            nic_on_boot: True
        cloud_init:
          host_name: "{{ item.name }}"
          user_name: ansible

# Passwd generated with mkpasswd -m SHA-512 alumno2020
# Clear text password is: alumno2020
          root_password: $6$3diC789eX$WZPkCdIrIm11cbZyhx/uwsydqgqEb1hsBvOXIF31ngjqxYhGyXMdaHZrwsf8vZHqEBoqPoXhWANPR/itAEU7l.

          authorized_ssh_keys: "{{ ssh_keys }}"
          custom_script: |
            write_files:
              - path: /etc/sudoers.d/ansible
                permissions: '0644'
                content: |
                  ansible ALL=(ALL) NOPASSWD:ALL
              - path: /tmp/saludos.txt
                permissions: '0644'
                content: |
                  "Que pasa, Oveja"
            runcmd:
              - sed -i '/AllowUsers/c\AllowUsers adminstic usuario soporteiass ansible' /etc/ssh/sshd_config
              - systemctl restart sshd
        wait: yes
      with_items: "{{ nodes }}"

    - name: Cleanup IaaS auth token
      ovirt_auth:
        ovirt_auth: "{{ ovirt_auth }}"
        state: absent
